{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event set generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from climada.hazard import TCTracks, TropCyclone, Centroids\n",
    "from climada.entity import Exposures\n",
    "from climada.entity.exposures import LitPop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set parameters\n",
    "# Exposure\n",
    "my_country = 'aus'\n",
    "m, n = 1,1 # based on analysis by Eberenz et al. (2020), (1,1) is the best combination.\n",
    "my_fin_mode = 'pc'\n",
    "ref_year = 2023\n",
    "\n",
    "# Hazard\n",
    "start_year = 1980\n",
    "end_year = 2023\n",
    "n_synth_tracks = 1000\n",
    "\n",
    "my_res_arcsec = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = LitPop.from_countries(my_country, my_res_arcsec, (m,n), my_fin_mode, reference_year = ref_year)\n",
    "exp1.check()\n",
    "\n",
    "# Remove Lord Howe Island and Macquarie Island\n",
    "exp = Exposures(exp1.gdf[exp1.geometry.x <= 155])\n",
    "exp.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hazard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracks_in_exp(tracks, exposure, buffer=1.0):\n",
    "    \"\"\"Select only the tracks that are in the vicinity (buffer) of an exposure.\n",
    "\n",
    "    Each exposure point/geometry is extended to a disc of radius `buffer`. Each track is\n",
    "    converted to a line and extended by a radius `buffer`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    exposure : Exposure\n",
    "        Exposure used to select tracks.\n",
    "    buffer : float, optional\n",
    "        Size of buffer around exposure geometries (in the units of `exposure.crs`),\n",
    "        see `geopandas.distance`. Default: 1.0\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    filtered_tracks : TCTracks\n",
    "        TCTracks object with tracks from tc_tracks intersecting the exposure whitin a buffer\n",
    "        distance.\n",
    "    \"\"\"\n",
    "\n",
    "    if buffer <= 0.0:\n",
    "        raise ValueError(f\"buffer={buffer} is invalid, must be above zero.\")\n",
    "    try:\n",
    "        exposure.geometry\n",
    "    except AttributeError:\n",
    "        raise Exception(\"this is not an Exposures object\")\n",
    "\n",
    "    exp_buffer = exposure.gdf.buffer(distance=buffer, resolution=0)\n",
    "    exp_buffer = exp_buffer.unary_union\n",
    "\n",
    "    # 'split_lines_antimeridian=False' is used to avoid a bug in current CLIMADA / geopandas version\n",
    "    tc_tracks_lines = tracks.to_geodataframe(split_lines_antimeridian=False).buffer(distance=buffer)\n",
    "    select_tracks = tc_tracks_lines.intersects(exp_buffer)\n",
    "    tracks_in_exp = [track for j, track in enumerate(tracks.data) if select_tracks[j]]\n",
    "    filtered_tracks = TCTracks(tracks_in_exp)\n",
    "\n",
    "    return filtered_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = TCTracks.from_ibtracs_netcdf(year_range = (start_year, end_year))\n",
    "my_tracks = tracks_in_exp(tracks, exp)\n",
    "\n",
    "print(f'Total number of historical tracks: {tracks.size}')\n",
    "print(f'Number of historical tracks in {my_country}: {my_tracks.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic tracks\n",
    "my_tracks.equal_timestep()\n",
    "my_tracks.calc_perturbed_trajectories(nb_synth_tracks = n_synth_tracks, decay=False);\n",
    "\n",
    "print(f'Number of tracks in {my_country} (inc. synthetic): {my_tracks.size:,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = 1.0\n",
    "lon = exp.geometry.x\n",
    "lat = exp.geometry.y\n",
    "polygon = (lon.min() - buffer, lat.min() - buffer, lon.max() + buffer, lat.max() + buffer)\n",
    "\n",
    "# Centroids\n",
    "cent = Centroids.from_pnt_bounds(polygon, res=my_res_arcsec/3600)\n",
    "cent.set_on_land()\n",
    "cent.set_region_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tctracks_to_tropcyclone_in_batches(i, track_batch, cent):\n",
    "    haz_batch = TropCyclone.from_tracks(track_batch, centroids=cent, intensity_thres=10.0)\n",
    "    haz_batch.write_hdf5(f'Hazards/haz_{my_country}_{n_synth_tracks}synth_part_{i}.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = (n_synth_tracks + 1) * 1\n",
    "num_batches = len(my_tracks.data) // batch_size\n",
    "track_batches = [TCTracks(my_tracks.data[i * batch_size:min((i + 1) * batch_size, len(my_tracks.data))]) for i in range(num_batches)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parallel(n_jobs=8)(\n",
    "    delayed(convert_tctracks_to_tropcyclone_in_batches)(i, track_batch, cent)\n",
    "    for i, track_batch in enumerate(track_batches)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the TropCyclone batches into one object\n",
    "files = [f'Hazards/haz_{my_country}_{n_synth_tracks}synth_part_{i}.hdf5' for i in range(num_batches)]\n",
    "haz = TropCyclone.concat([TropCyclone.from_hdf5(file) for file in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haz.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save hazard\n",
    "haz.write_hdf5(f'Hazards/haz_{my_country}_{n_synth_tracks}synth.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
